# -*- coding: utf-8 -*-
"""PPM - Titanic

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_qzwetpNjwrR5TdFrwRtoGeFm-ReGsaW

#Preprocess
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.impute import KNNImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler

df_train = pd.read_csv('train (1).csv')
df_test = pd.read_csv('test (1).csv')

df_train.head()

df_train.describe(include=['O'])

df_train.describe()

columns_to_drop = ['Name', 'PassengerId']
df_train.drop(columns=columns_to_drop, inplace=True)
df_test.drop(columns=columns_to_drop, inplace=True)

plot_df = df_train.Transported.value_counts()
plot_df.plot(kind="bar")

"""##Numerical data

Numerical data terdiri dari age, room service, food court, shopping mall, spa, dan vrdeck
"""

sns.histplot(data=df_train, x='Age')
plt.show()

columns_to_fill = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']
knn_imputer = KNNImputer(n_neighbors=2)
df_train[columns_to_fill] = knn_imputer.fit_transform(df_train[columns_to_fill])
df_test[columns_to_fill] = knn_imputer.fit_transform(df_test[columns_to_fill])

num_bins = 5
df_train['Age'] = pd.cut(df_train['Age'], bins=num_bins, labels=False)
df_test['Age'] = pd.cut(df_test['Age'], bins=num_bins, labels=False)
df_train.head()

df_train.isnull().sum()

"""##Categorical data"""

df_train['HomePlanet'].unique()

df_train['CryoSleep'].unique()

df_train['Destination'].unique()

df_train['VIP'].unique()

df_train['Cabin'].unique()

df_train[['Deck', 'Num', 'Side']] = df_train['Cabin'].str.split('/', expand=True)
df_test[['Deck', 'Num', 'Side']] = df_test['Cabin'].str.split('/', expand=True)
df_train.head()

df_train.drop(columns=['Cabin'], inplace=True)
df_test.drop(columns=['Cabin'], inplace=True)

# grouped = df_train.groupby('Side')['Transported'].value_counts().unstack().fillna(0)
# print(grouped)

# cat_columns = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']
# label_encoder = LabelEncoder()
# for column in cat_columns:
#     df_train[column] = label_encoder.fit_transform(df_train[column])
#     df_test[column] = label_encoder.fit_transform(df_test[column])

cat_columns = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']
for column in cat_columns:
    most_frequent = df_train[column].mode()[0]
    df_train[column].fillna(most_frequent, inplace=True)

for column in cat_columns:
    most_frequent = df_test[column].mode()[0]
    df_test[column].fillna(most_frequent, inplace=True)

columns_to_fill = ['Num']
knn_imputer = KNNImputer(n_neighbors=2)
df_train[columns_to_fill] = knn_imputer.fit_transform(df_train[columns_to_fill])
df_test[columns_to_fill] = knn_imputer.fit_transform(df_test[columns_to_fill])

df_train.isnull().sum()

df_train_encoded = pd.get_dummies(df_train, columns=cat_columns, drop_first=True)
df_test_encoded = pd.get_dummies(df_test, columns=cat_columns, drop_first=True)
df_train_encoded.head()

scaler = StandardScaler()

columns_to_scale = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Num']
df_train_encoded[columns_to_scale] = scaler.fit_transform(df_train_encoded[columns_to_scale])
df_test_encoded[columns_to_scale] = scaler.fit_transform(df_test_encoded[columns_to_scale])
df_train_encoded.head()

"""#Modelling"""

pip install catboost

from sklearn.svm import SVC, LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import GradientBoostingClassifier
import xgboost as xgb
from xgboost import XGBClassifier
import catboost as cb
from catboost import CatBoostClassifier
import lightgbm as lgb
from lightgbm import LGBMClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.model_selection import train_test_split

X_train = df_train_encoded.drop(['Transported'], axis=1)
y_train = df_train_encoded['Transported']
X_test = df_test_encoded.copy()
X_train.shape, y_train.shape, X_test.shape

svc = SVC()
svc.fit(X_train, y_train)
svm_pred = svc.predict(X_test)
score_svc = svc.score(X_train, y_train)
score_svc

knn = KNeighborsClassifier(n_neighbors = 3)
knn.fit(X_train, y_train)
knn_pred = knn.predict(X_test)
score_knn = knn.score(X_train, y_train)
score_knn

gaussian = GaussianNB()
gaussian.fit(X_train, y_train)
nb_pred = gaussian.predict(X_test)
score_gaussian = gaussian.score(X_train, y_train)
score_gaussian

dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
dt_pred = dt.predict(X_test)
score_dt = dt.score(X_train, y_train)
score_dt

random_forest = RandomForestClassifier()
random_forest.fit(X_train, y_train)
rf_pred = random_forest.predict(X_test)
random_forest.score(X_train, y_train)
score_rf = random_forest.score(X_train, y_train)
score_rf

ada_boost = AdaBoostClassifier()
ada_boost.fit(X_train, y_train)
ada_pred = ada_boost.predict(X_test)
ada_boost.score(X_train, y_train)
score_ab = ada_boost.score(X_train, y_train)
score_ab

gb = GradientBoostingClassifier()
gb.fit(X_train,y_train)
gb_pred = gb.predict(X_test)
print(gb.score(X_train, y_train))

xgboost_model = XGBClassifier()
xgboost_model.fit(X_train, y_train)
xgb_pred = xgboost_model.predict(X_test)
print(xgboost_model.score(X_train, y_train))

lgbm_model = LGBMClassifier()
lgbm_model.fit(X_train, y_train)
lgbm_pred = lgbm_model.predict(X_test)
print(lgbm_model.score(X_train, y_train))

catboost_model = CatBoostClassifier(verbose=0)
catboost_model.fit(X_train, y_train)
catboost_pred = catboost_model.predict(X_test)
print(catboost_model.score(X_train, y_train))

lgbm = LGBMClassifier(**{
    'objective': 'binary',
    'boosting_type': 'gbdt',
    'metric': 'auc',
    'random_state': 42,
    'colsample_bytree': 0.56,
    'subsample': 0.35,
    'learning_rate': 0.05,
    'max_depth': 8,
    'n_estimators': 1000,
    'num_leaves': 140,
    'reg_alpha': 0.14,
    'reg_lambda': 0.85,
    'verbosity': -1
})

xgb = XGBClassifier(**{
    'objective': 'binary:logistic',
    'eval_metric': 'auc',
    'random_state': 42,
    'colsample_bytree': 0.25,
    'learning_rate': 0.07,
    'max_depth': 8,
    'n_estimators': 800,
    'reg_alpha': 0.09,
    'reg_lambda': 0.70,
    'min_child_weight': 22,
    'verbosity': 0
})

cat = CatBoostClassifier(**{
    'iterations': 10000,
    'objective': 'Logloss',
    'eval_metric': 'AUC',
    'early_stopping_rounds': 1000,
    'bagging_temperature': 0.1,
    'colsample_bylevel': 0.88,
    'iterations': 1000,
    'learning_rate': 0.065,
    'max_depth': 7,
    'l2_leaf_reg': 1,
    'min_data_in_leaf': 25,
    'random_strength': 0.1,
    'max_bin': 100,
    'verbose': 0
})

# Initialize the voting classifier
vote = VotingClassifier(estimators=[('lgbm', lgbm), ('xgb', xgb), ('cat', cat)], voting='soft')

# Initialize an empty array to hold the submission predictions
submission_predictions = []

# Initialize RepeatedStratifiedKFold
kf = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)

# Save AUCs
aucs = []
ind = 1

# Loop through each fold
for train_index, test_index in kf.split(X_train, y_train):
    print(f"============== Working on fold #{ind} ================")
    X_train_kf, X_val_kf = X_train.iloc[train_index], X_train.iloc[test_index]
    y_train_kf, y_val_kf = y_train.iloc[train_index], y_train.iloc[test_index]

    print()
    print("               Fitting the voting model...              ")
    # Fit the model
    vote.fit(X_train_kf, y_train_kf)

    print()
    print("            Predicting on the validation data           ")
    # Predict probabilities for validation set
    y_pred_val = vote.predict_proba(X_val_kf)[:, 1]

    # Calculate AUC for validation set
    auc_val = roc_auc_score(y_val_kf, y_pred_val)
    print()
    print(f"           Validation ROC AUC Score: {auc_val}        ")

    aucs.append(auc_val)

    print()
    print("             Predicting on submission data...")
    # Predict probabilities for test set (df_test)
    y_pred_test = vote.predict_proba(X_test)[:, 1]
    submission_predictions.append(y_pred_test)

    print()
    print(f"                 Fold #{ind} finished !                ")

    ind += 1

"""#Submit to Kaggle"""

submission_sample = pd.read_csv('sample_submission (1).csv')

df_final = pd.DataFrame({ "PassengerId": submission_sample["PassengerId"],"Transported": gb_pred})
df_final

df_final['Transported'] = df_final['Transported'].replace({0: False, 1:True})
df_final

df_final.to_csv('gb.csv', index=False)

print(f"Average ROC AUC Score: {sum(aucs) / len(aucs)}")

# Average predictions from different folds
avg_submission = pd.DataFrame(submission_predictions).mean(axis=0)

submission_sample["Transported"] = avg_submission

submission_sample.head()

threshold = 0.5

submission_sample['Transported'] = submission_sample['Transported'] > threshold

submission_sample.head()

# Save submission to CSV
submission_sample.to_csv("ensemble_lgbm_cb_xgb_one_hot_encoding.csv", index=False)

